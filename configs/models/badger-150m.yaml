model_name: badger-150m
tokenizer_name: gpt2
model_config:
  _name_: lm
  d_model: 864 
  d_inner: 1728 
  n_layer: 18
  vocab_size: 50257
  embed_dropout: 0.0
  layer:
    _name_: multihyena
    emb_dim: 33 
    filter_order: 64 
    local_order: 3
    num_heads: 8
    l_max: 2048
    fused_fft_conv: False
    modulate: True
    w: 14
  fused_mlp: True
  fused_dropout_add_ln: True
  residual_in_fp32: True
  pad_vocab_size_multiple: 8

postprocess_cfg:
  _name_: distill-conv
  distill_path: /mnt/safari-internal/artifacts/laughing_hyena/distilled/badger/modal/4/
  distill_cfg:
    _name_: laughing-hyena-modal-filter
    order: 4
    num_filters: 108
    real_fft: False